
This is supposed to be an article about libwww-perl-6 for the Perl
conference in august 1998.

# $Id$

=pod

Title: LWPng ...

Author: Gisle Aas <aas@sn.no>

=head1 Abstract

This article describe a redesign of the libwww-perl library in order
to provide support for writing HTTP/1.1 clients that can manage
multiple persistent connections to the servers it communicate with.  The
redesign is based on the adoption of an event loop framework.

=head1 Introduction

The libwww-perl package has been quite successful at implementing a
wide range of web client applications and also as a support tool for
server side programs and programmers.  One important feature that it
has been lacking is support of the new version of the HTTP protocol,
HTTP/1.1.

=head1 A short history of HTTP

HTTP is a simple protocol based on the request/response paradigm.  A
client establishes a connection with a server and sends a request
message to the server.  The server then returns a response message.

HTTP started out as an extremely simple protocol where the client
connected to a server, sent a line with "GET <name>" and the server
returned the <name> resource and closed the connection.  This version
of the protocol has afterwards been dubbed HTTP/0.9.

The next revision gave us HTTP/1.0, which is still what is deployed in
most servers and clients today [ref].  It adds a protocol version
number to the request line from the client and adds MIME-like messages
for both the request from the client and the response from the server.
This makes it possible to add extra information about
request/responses and to carry meta-information about the content of
these messages.  Responses now also start with a status line with a
status code that encode the overall outcome of the request.  These
enhancements also make the protocol extensible.

The next step was/is HTTP/1.1 which tries to fix some of the
shortcommings of the HTTP/1.0 protocol [ref]. One simple but important
change is that the Host header is now mandatory. This make it possible
to serve multiple domains from a single server without allocating a
new IP-address to each.  Another change is support for partial
content.  The support for caching and proxies has also been much
clarified and improved on.  There is also a standard mechanism of
switching away from HTTP/1.1 to some other (hopefully more suitable)
protocol on the wire.

The most important change with HTTP/1.1 is the introduction of
persistent connections.  This means that more than one
request/response exchange can take place on a single TCP connection
between a client and a server.  This improves performance and
generally interacts much better with how TCP works underneath.  This
also means that the peers must have some way to tell the extent of the
messages on the wire. In HTTP/1.0 the only way to do this was by using
the Content-Length header and by closing the connection (which was
only an option for the server).  Use of the Content-Length header is
not appropriate when the length of the message can not be determined
in advance.  HTTP/1.1 introduce two new ways to delimit messages; the
chunked transfer encoding and the self delimiting multipart content
types.  The chunked transfer encoding means that the message is broken
into chunks, each of arbitrary size and each preceded by a line
specifying the number of bytes in the chunk.  The multipart types use
a special boundary bytepattern as a delimiter for the messages.

With persistent connections one can improve performance even more by
the use of a technique called "pipelining".  This means that the
client sends multiple requests down the connections without waiting
for the response of the first request before sending the second and so
on.  This can have a dramatic effect on the thoughput for high latency
links. [ref NOTE-pipelining-970624]

Some of the HTTP/1.1 features are also deployed in HTTP/1.0 clients
and servers.  Persistent connections can sometimes be used with
HTTP/1.0 if the clients sends a "Connection: Keep-Alive" header.  Most
of todays HTTP/1.0 clients send the Host header.

HTTP/NG is still a research project and an attempt to take a more
radical approach.  The main "features" is making the protocol binary
in order not to waste bytes on long human readable headers and direct
support for multiplexing over a single network connection.  It is not
clear whether this is such a big win. [ref]

=head1 History of libwww-perl

The libwww-perl project started on the first WWW conference in Geneva
where Martijn Koster discussed MOMspider with Roy Fielding.  Martijn
suggested that it would be a good thing if the reuseable components of
this program was broken out into a library.  The result was the
libwww-perl library for perl4 that Roy maintained (and still does).

At one point both Gisle and Martijn had made their own modulifications
of Roy's library to better suit the possibilities that perl5 provided.
We joined forces and made several alpha releases together.  Martijn
had a little disagreement about rights to library souce code with his
employer at that time.  This was the main reason Gisle ended up as the
maintainer of the package.

The LWP:: module name was introduced by Martijn in one of the pre
alpha releases.  It was early pointed out that this name could be
confused with what some implementations of threads called themselves,
but no better name alternatives emerged.  The last messages on this
matter was <"6362 Tue Jul 18 09:59:46 1995"@mhs-relay.ac.uk> where
Martijn concluded that "OK, so we all agree lwp stinks :-)".  The name
stuck.

At 1996-05-26 we made the first non-beta release of libwww-perl.  It
was called release 5.00 because it was for perl5 and in order to make
some room for Roy to maintain libwww-perl for perl4 which at that time
was (and still is) called libwww-perl-0.40.

In the two years that has passed since that time lots of bugs has been
fixed and some features added, but nothing radical has happened.  We
have not been eager to try to adopt HTTP/1.1 features because it
seemed clear that decent support could not be achieved without a
larger restructuring of how the basic protocol services was
implemented.

One important work that inspired the rewrite described here was Marc
Langheinrich's ParallelUserAgent implementation.  It extended
libwww-perl with the possibility to access multiple servers (or have
multiple connections to the same server) at the same time. [ref]

In the november 1997 Gisle started on a rewrite of how the basic
services provided by libwww-perl worked.  The goal was to provide full
HTTP/1.1 client support and at the same time make the library both
more flexible and (optionally) more lightweight.  Nothing much
happened until march 1998, but then I finally got opportunity and
currage enough to start working on this fulltime and it is now
quite useable.  This work is currently distributed under the name
LWPng, but is expected to become libwww-perl-6 when the beta phase is
over.


=head1 A short introduction to libwww-perl-5

The libwww-perl library is based on HTTP style communication.  The
main model is that all requests through any protocol module are forced
into an HTTP straightjacket. This makes things very easy, consistent,
and nice.  This model is also what libwww-perl has inherited from and has
in common with w3c-libwww [ref].

LWP provide an object oriented model of HTTP style messages that are
passed between servers and clients.  The I<HTTP::Request> class models
the message sent from a client to a server.  The I<HTTP::Response>
class models the message send back from a server to a client.  On
their way between a client to a server these messages are converted to
the actual protocol on the wire which will depend on what kind of
server we are accessing (i.e. does not have to be HTTP).

Instances of the I<LWP::UserAgent> class are created by client
applications and have the role as the interface between the
application and a network of accessible servers.  The
I<LWP::UserAgent> provide the request() method that accepts an
I<HTTP::Request> object as argument and will (eventually) return a
I<HTTP::Response> object when the corresponding server returns an
answer.

The canonical example of LWP client usage looks like this:

  use LWP::UserAgent;
  my $ua = LWP::UserAgent->new;

  my $req = HTTP::Request->new(GET => 'http://www.linpro.no/lwp/');
  $req->header(Accept => 'text/html');

  # send request, get response
  my $res = $ua->request($req);

  # check the outcome
  if ($res->is_success) {
     print $res->content;
  } else {
     print "Error: " . $res->status_line . "\n";
  }

The I<HTTP::Daemon> class provide the corresponding interface for
server applications.  Through instances of this class a server
application will get hold of a connection initiated by a client and
will be able receive I<HTTP::Request> objects from this connection and
send back I<HTTP::Reponse> objects.  Since the client and server
interface use the same message objects it is trivial to write simple
proxy[ref] type of applications [reference to Randals proxy for
WebTechniques].

[Feature list?]


=head1 LWPng design

It became evident that a major redesign of the underlying protocol
modules and the main interfaces was needed in order to support
HTTP/1.1 clients well. The major shift was that we now wanted to be
able to transparently support multiple persistent connections and that
these connections should be used efficiently (i.e. we should be able
to support pipelining too).

As for LWP5, the programming interface still ought to hide the details
of connection creation and destruction, but in order to make the
library able to efficiently utilize the multiple persistent
connections it had to have more than a single request to work with at
time.  The main idea would be that the application fed the library
with all the request objects to be carried out and that the library
would try to use its connections to the servers as optimally as
possible.  The optimization would be guided by various parameters
(throughput, speed, limit number of connections, etc.).

Some other design goals and guidelines included.

=over 2

=item *

The abstractions provided should be fairly high level.  The
HTTP::Request and HTTP::Response object interfaces of LWP5 have shown
themselves to work well and be valuable.  We still wanted a design
based on passing these objects around.

=item *

The redesigned library should be no more difficult than the old LWP5
to use.  The application programmer should not have to work harder.

=item *

The redesigned libraray should be backwards compatible with LWP5.  Old
applications should continue to run, but it is generally OK if they do
not run as efficiently as applications that have been rewritten to the
new interface.

=item *

The library implementation should be efficient.  The main issues are
startup time for applications (i.e. not too much unused source code
for perl to compile).  Effient use of the network connections and the
operating system (i.e. not many small read/write requests and no
polling.)

=item *

We wanted to use this opportunity to generalize some parts of the
interfaces more.  For instance the old $ua->from and $ua->agent
methods can be generalized to something that is able to set up default
headers that are added to requests before they are sent out.  Having
this also solve much of the problem of setting up authorization
headers in request.

=item *

Optional features of the library should add minimal penalty to
applications that don't use them.

=item *

Most features of the library should be made optional.

This hopefully interacts well with the preceding point and should
allow a wider range of HTTP client applications to be built.  The
library can be comprehensive and featureful and still useable by
small/simple applications that mainly care about speed.  They should
not shy away from LWP because it is too big and too slow to start.

=item *

"Easy things should be easy, hard things possible."  This is a Perl
slogan that I agree with and that also hopefully applies to this
design.

=item *

There should be minimal bindings between modules and classes.  One should be
able to use only the wanted part of the library and individual modules
should be usable in other context than LWP.

=item *

There should be no need for signal handling and no uses of alarm to
implement timeouts.

One of the things that created much problems for LWP5 was that it
earlier used alarms to implement timeouts.  This was problematic both
because it is not available everywere and because the perl signal
handling is not reliable.

=item *

Happy coexistence with the Tk module.  One should be able to write
client applications that have GUIs.

=back


=head1 Event driven programming

A prerequisite for supporting the persistent connections that
HTTP/1.1 requires, is to be able to handle both reading and writing
from multiple network connections at the same time.  One would also
like to manage idle connections with some timeout and to notice
when/if the server decide to close the connections.  These
requirements basically means the adoption of an event driven model or
a model based on separate threads of control.  We have chosen to go
for the event driven model.  Thread support is still new to Perl
and will not work everywhere when available.  An event-driven
framework will continue to work with threaded Perls.  A threaded
framework would require a thread enabled Perl to run.

[Mention problems with event oriented programming.  Must explicitly
store lot of state between invocations of the event handlers.
Handlers must be written to return quickly or special care must be
taken when allowing prompting/nested event loops.  With an threaded
environment the state can be embedded as the natural flow the program,
but one will experience new problems related to synchronization and
protecting agains races.]

Let us start by investigating the impact of the event driven framework
on the overall LWP programming model.  The basic model for sending
requests and receving respones in LWP5 used to be:

  $res = $ua->request($req);   # return when response is available
  if ($res->is_success) {
      #...
  }

With the new event driven framework it becomes:

  $ua->spool($req1);   # returns immediately
  $ua->spool($req2);   # can send multiple request in parallel
  #...

  mainloop->run;       # return when all connections are gone

Request objects are created and then handed off to the $ua which will
queue them up for processing.  As you can see, there is no longer any
natural place to test the outcome of the requests since the spool()
method returns before the response is available.  What happen is that
the requests live their own lives and they will be notified (though a
callback method call) when the corresponding responses are available.
The application programmer will have to set up handlers (in the
requests) that react to these events.

Luckily, this does not mean that all old programs must be rewritten.
The following show one way to emulate something very similar to the old
behaviour:

  my $req = LWP::Request->new(GET => $url);

  # $res = $ua->request($req);
  my $res;
  # set up a handler to be invoked when the response is available.
  $req->{done_cb} = sub { $res = shift; };

  $ua->spool($req);
  mainloop->one_event until $res;  # runs until response is available

  if ($res->is_success) {
      #...
  }

and this will in fact be used to emulate the old $ua->request() and
$ua->simple_request() interfaces for compatibility purposes.

The current LWPng implementation and the examples above are based on
the event loop implementation provided by the LWP::EventLoop class.
It is small, simple and support exactly what LWPng needs and not much
more.  The main problem is that this introduce yet another event loop
and that it will create problems if the application want to use LWPng
together with modules based on a different event loop.

[Discuss other event loops in Perl modules.  The one provided by Tk.
Grahams Event.  EventServer.  And chances for getting a standard
eventloop mechanism adopted by the Perl core.  Tcl have done this.]


=head1 Major classes

LWPng continue in the object oriented tradition of LWP5 and it adds
some new classes.  Some of these replace the corresponding classes in
LWP5.  Some add features not present before.

One important design criteria is to stay backwards compatible.  It
means that the old interfaces must be kept and if we want to clean up
an interface we basically have to start afresh with a new class
name. This allows old code to continue to work because it still use
the old names.  Often it is a good idea to reimplement the old
interfaces on top of the new interface. This allows us to keep
backwards compatibility, get one place to fix bugs and at the same
time allow new code to not suffer from compatibility bloat.  It also
works as validation of the generality of the new interfaces.

The classes that have changed name and interfaces are:

=over 2

=item *

The old LWP::UserAgent has become LWP::UA.  The name was changed
because we wanted to make a general cleanup of the interface.  The
name change also make the transition period easier as the old LWP5
library can be installed together with the new library.

=item *

The old LWP::Protocol::* modules has been replaced with LWP::Conn::*
modules.  The event oriented framework requires a completely different
interface towards and from the low level modules.  Both versions must
be able to work side by side for some time.

=item * 

The LWP::Authen modules has also changed interface and therefore name.
We have kept the prefix, but will now use all lower case for the
scheme name.

=back

Completely new classes include:

=over 2

=item *

LWP::Request - this is a subclass of HTTP::Request that allows us to
attach response handlers and callbacks to these objects.  Basically all
the parameters given (and returned) by the old $ua->request method
must now be represented as attributes of the request object.

=item *

URI::Attr - this class make it possible to attach attributes based on
hierarchical levels of the URI name space.  It is used for various
configurations and for remembering facts about places in this space.
The main benefit is that it allows more generalizations of the
interface.

=item *

LWP::Hooks is a mixin class that allow handlers to be dynamically
registered on the object and executed.  LWP::UA and LWP::Request
inherit its methods.

=item *

LWP::StdSched - Policy decisions about how many and which connections
to set up or tear down at given point are delegated to a special
scheduler object by the LWP::UA.  This arangement allow this behaviour
to be easily replaced or updated.  The LWP::StdSched is a simple
scheduler that tries to adhere to various limits on the number of
connections to create.

=item *

LWP::Sink - HTTP concepts like chained Transfer-Encoding and
Content-Encoding suggest that we need a way to transform the message
content back to its original form.  Since we also want to be able to
handle arbitrary sized content and to be able to make the content
available to the application as early as possible a stream based
organization of transformation modules is handy.  The LWP::Sink is a
base class for the the input side of a stream module.

=item *

LWP::EventLoop has been mentioned before.  It is basically just a
wrapper around the select system call.

=back

We will now investigate the major interfaces of these classes in some
more detail.

=head2 LWP::UA

The LWP::UA represents the main interface of the client library.  The main
entry point is the spool() method.  All requests to be processed by the
library enter through this "gate".  Before a request is handed over to some
protocol module the LWP::UA will invoke any I<spool_handlers> registered.
The handlers are simply a list of subroutines and can be registered
dynamically by the application.

These handlers is the main stategy of how we implement optional features and
how we achieve zero overhead for applications that don't use the features.
The bare LWP::UA is only capable of doing the following basic things:

=over 3

=item 1.

It provide the spool() method.

=item 2.

It know how to run any handlers registered.

=item 3.

If no handler signaled that the request has been handeled, then
it knows how to dynamically load a protocol module by looking at the scheme
of the URL and to pass the requests too them.

=item 4.

It tells the scheduler object to take some action ($sched->reschedule).

=back

[One might argue that 3. and 4. could also be replaced by one or more
handlers.]

The handlers are invoked with a reference to the UA and a reference to the
request as arguments.  If a handler return a TRUE value, then it signals
that the request has been handeled and no further handlers are to be invoked
for it.  Handlers are also used to modify the request on its way (for
instance adding headers).  They can register response callbacks or response
handlers to be triggered when the response is available.

[One can contrast this with handlers within the Apache web server for
instace.]

The following handlers are currently provided by the library.  Handlers which
are not used does not have to be loaded either (i.e. Perl does not waste
time compiling their code).  Many of the handlers use the URI::Attr object
member of the UA to obtain the configuration information.

=over 4

=item default_headers

This handler add static headers to a request where these headers are not
already present.  It it used to add headers like C<User-Agent> and C<From>.

=item date

This handler add a U<Date> header to the request if applicable.  Not really
very useful, but shows how to write small handlers to cope with headers
that the I<default_headers> handler can't do.

=item authentication

This handler try to add Authorization headers to the request that we know
might need it.  It looks up realm for the URL and map this to some Authen
object that can add the corresponding header.  This works together with the
Authenticate response handler.

=item proxy

This handler try to add the proxy attribute of a request.  The proxy
configuation might indicate that some URLs are to be passed through a proxy.

=item head_parser

This handler register a response data handler with the request.  The
registered handler will create a HTML::Parser object if the response
contains an HTML document and pass the first few chunks of document data
through it.

=item cookies

This handler will let an HTTP::Cookies object add C<Cookie> headers to the
request and will also register a response callback that will let the
HTTP::Cookies object extract any C<Set-Cookie> headers.

=back
   
Some other ideas for response handlers might include:

=over 4

=item local cache

check if we have a local copy of the response and return it instead.  If no
valid local copy exists register a response handler to update or validate
the local cache.  Might also add If-None-Match or If-Modified-Since headers
to the request when we have a stale local copy.

=item specific scheme handling

an application might for instance want to handle <about:> URLs similar to
what Netscape does by registering a handler.

=item url rewriting

implement automatic fast redirection inside the client

=item netnanny

block indecent parts of the URI space

=back

Scheduler parameters.  max_conn/max_conn_per_server.  Mention
scheduler again.

The semi internal LWP::Server class.  LWP::UA manitains a list of servers
that it shall/have communicated with.  Connection parameters per server (why
not use the URI::Attr for this?)

The stop method will when invoked (prematuterly) terminate all
on-going requests, i.e. all requests return immediately with an error
response and all network connections are killed.


=head2 URI::Attr

For many situations we have found a need to set up configuration parameters
and other attributes related to the URI name space.  Many of the handlers
should work differently depending on scheme, host or path.  For example the
authentication handler might want to remeber "realms" per server and
remember which path prefixes that is protected within the different realms.

=head2 LWP::Request

LWP::Request response handlers and callbacks.  List handlers present.

   - extract_cookies
   - redirect handler
   - authentication handler

Both "response_data" and "response_done" hooks in addition to
"response_handler".  Only the handler is copied on cloning (and thus
present in followup responses).  Another difference if whether the
return value matters.

managed_by attribute (ua).  Mainly used to be able to spool followup
requests.

priority/proxy attributes.

=head2 LWP::Conn object interface.

The guts of the library is the LWP::Conn classes.  This is where all the
action (i.e. low level protocol handling) takes place.  The basic model is
that the LWP::Conn's are what drive the activity (together with $ua->spool).


          +--> lwp::ua ---+
          |               |
      application      lwp::conn
          |               |
        (g)ui          network
          ^               ^
          |               |
          +-- eventloop --+
                  |
           external stimuli

How these can be used on their own without the rest of the library.

=head2 LWP::Conn::HTTP design.

Cool.  The flexibility of Perl continue too
suprise me.

Perhaps we need a redisign to be able to support HTTPS?  Don't let the
LWP::Conn:HTTP object be the actual handle, but use a member object
instance insted.

=head2 streams/LWP::Sink

process arbitrary sized objects and make the result
available for further processing as early as possible.


=head1 Some benchmarks

How well does it perform piplining.  Compare it with LWP5 and
w3c-libwww perhaps.


=head1 Conclusions

This article has discussed the design of HTTP/1.1 support for the next
generation of the LWP modules.

=cut
