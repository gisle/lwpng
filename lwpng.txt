# $Id$
# This is supposed to be an article about libwww-perl-6 for the Perl
# conference in August 1998.


=head1 Title: LWPng - Adding HTTP/1.1 support to libwww-perl

=head2 Author: Gisle Aas <aas@sn.no>

=begin pc98submissions@perl.org

(no affiliation)

Contact information:

  Email:  aas@sn.no
  Phone:  +47 5533 0252

  Smail:  Gisle Aas
          Furubotn 42
          N-5082 Eidsvågneset
          Norway

=end pc98submissions@perl.org


=head1 Abstract

The I<libwww-perl> library (often abbreviated LWP) is a collection of
Perl modules which provides a simple and consistent programming
interface to the World-Wide Web.  The library is currently in use for
a wide range of Web applications [0].

This article describes a redesign of the libwww-perl library in order
to provide support for writing HTTP/1.1 clients.  The new library
allows client applications to utilize multiple persistent connections
to the servers it communicates with.  The redesign is based on the
adoption of an event driven framework.  Requests are registered with
the library and will receive callback events as the responses come
back from the server(s).  The library try to match the registered
requests with the the persistent connections it has available and will
create new connections when necessary.



=head1 Introduction

Libwww-perl is a collection of Perl modules which provides a simple
and consistent programming interface (API) to the World-Wide Web.  The
main focus of the library is to provide classes and functions that
allow you to write WWW clients, thus libwww-perl is said to be a WWW
client library. The library also contains modules that are of more
general use and even classes that help you implement simple HTTP
servers.

The libwww-perl package has been quite successful at implementing a
wide range of web client applications and also as a support tool for
server side programs and programmers.  One important feature that it
has been lacking is support for the new version of the HTTP protocol,
HTTP/1.1.

=head1 A short history of HTTP

HTTP is a simple protocol based on the request/response paradigm.  A
client establishes a connection with a server and sends a request
message to the server.  The server then returns a response message.

HTTP started out as an extremely simple protocol where the client
connected to a server, sent a line with "GET <name>" and the server
returned the <name> resource and closed the connection.  This version
of the protocol has afterwards been dubbed HTTP/0.9.

The next revision gave us HTTP/1.0, which is still what is deployed in
most servers and clients today [1].  It adds a protocol version number
and MIME-like messages for both the request from the client and the
response from the server [2].  This makes it possible to add extra
information about request/responses and to carry meta-information
about the content of these messages.  Responses now also start with a
status line with a status code that encodes the overall outcome of the
request.  These enhancements make the protocol extensible.

The next step was/is HTTP/1.1 which tries to fix some of the
shortcomings of the HTTP/1.0 protocol [3,4]. One simple but important
change is that the Host header is now mandatory. This makes it possible
to serve multiple domains from a single server without allocating a
new IP-address to each.  Another change is support for partial content
messages.  The support for caching and proxies has also been much
clarified and improved on.  There is also a standard mechanism of
switching away from HTTP/1.1 to some other (hopefully more suitable)
protocol on the wire.

The most important change with HTTP/1.1 is the introduction of
persistent connections.  This means that more than one
request/response exchange can take place on a single TCP connection
between a client and a server.  This improves performance and
generally interacts much better with how TCP works underneath.  In
order to be able to do this, the peers must have some way to tell the
extent of the messages on the wire. In HTTP/1.0 the only way to do
this was by either using the Content-Length header or by closing the
connection (which was only an option for the server).  Use of the
Content-Length header is not appropriate when the length of the
message can not be determined in advance.  HTTP/1.1 introduce two new
ways to delimit messages; the chunked transfer encoding and the self
delimiting multipart content types.  The chunked transfer encoding
means that the message is broken into chunks, each of arbitrary size
and each preceded by a line specifying the number of bytes in the
chunk.  The multipart types use a special boundary byte pattern as a
delimiter for the messages.

With persistent connections one can improve performance even more by
the use of a technique called "pipelining".  This means that the
client sends multiple requests down the connections without waiting
for the response of the first request before sending the second and so
on.  This can have a dramatic effect on the throughput for high latency
links [5].

Some of the HTTP/1.1 features are also deployed in HTTP/1.0 clients
and servers.  Persistent connections can sometimes be used with
HTTP/1.0 if the clients sends a "Connection: Keep-Alive" header.  Most
of todays HTTP/1.0 clients send the Host header.

HTTP/NG is still a research project and is an attempt to take a more
radical approach [6].  The main "features" is making the protocol
binary in order not to waste bytes on long human readable headers and
direct support for multiplexing over a single network connection.  It
is not clear that this will be a big enough win that the world ever
will move away from the HTTP/1.X protocol.


=head1 History of libwww-perl

The libwww-perl project started on the first WWW conference in 1994
(Geneva) where Martijn Koster discussed MOMspider with Roy Fielding.
Martijn suggested that it would be a good thing if the reusable
components of this program were broken out into a library.  The result
was the libwww-perl library for perl4 that Roy maintained (and still
does) [7,8].

At one point both Gisle and Martijn had made their own modifications
of Roy's library to better suit the possibilities that perl5 provided.
We joined forces and made several alpha releases together.
Unfortunately Martijn had a little disagreement with his employer
about the intelectual property rights to work done outside hours,
and to safeguard LWP's continued availability to the Perl community he
asked Gisle to take over maintenance of the package.

The C<LWP::> module name was introduced by Martijn in one of the alpha
releases.  It was early pointed out that this name could be confused
with what some implementations of threads called themselves, but no
better name alternatives emerged.  The last mailing list messages on
this matter was <"6362 Tue Jul 18 09:59:46 1995"@mhs-relay.ac.uk>
where Martijn concluded that "OK, so we all agree LWP stinks :-)".
The name stuck.

On 1996-05-26 we made the first non-beta release of libwww-perl.  It
was called release 5.00 because it was for perl5 and in order to make
some room for Roy to maintain libwww-perl for perl4 which at that time
was (and still is) called libwww-perl-0.40.

In the two years that has passed since that time lots of bugs has been
fixed and some features added, but nothing radical has happened.  We
have not been eager to try to adopt HTTP/1.1 features because it
seemed clear that decent support could not be achieved without a
larger restructuring of how the basic protocol services was
implemented.

One important work that inspired the rewrite described here was Marc
Langheinrich's ParallelUserAgent implementation.  It extended
libwww-perl with the possibility to access multiple servers (or have
multiple connections to the same server) at the same time. [9]

In November 1997 Gisle started on a rewrite of how the basic
services provided by libwww-perl worked.  The goal was to provide full
HTTP/1.1 client support and at the same time make the library both
more flexible and (optionally) more lightweight.  Little
happened until march 1998, but then I finally got opportunity and
tuits enough to start working on this full time and it is by this time
quite usable.  This work is currently distributed under the name
LWPng, but is expected to become libwww-perl-6 when its beta phase is
over.


=head1 A short introduction to libwww-perl-5

The libwww-perl library is based on HTTP style communication.  The
main model is that all requests through any protocol module are forced
into an HTTP straight-jacket. This makes things very easy, consistent,
and nice.  This model is also what libwww-perl has inherited from, and has
in common with, w3c-libwww [10].

LWP provides an object oriented model of HTTP style messages that are
passed between servers and clients.  The I<HTTP::Request> class models
the message sent from a client to a server.  The I<HTTP::Response>
class models the message sent back from a server to a client.  On
their way between a client to a server these messages are converted to
the actual protocol on the wire which again will depend on what kind of
server we are accessing (i.e. does not have to be HTTP).

Instances of the I<LWP::UserAgent> class are created by client
applications and serve as the interface between the
application and a network of accessible servers.  The
I<LWP::UserAgent> provides the request() method that accepts an
I<HTTP::Request> object as an argument and will (eventually) return a
I<HTTP::Response> object when the corresponding server returns an
answer.

The canonical example of LWP client usage looks like this:

  use LWP::UserAgent;
  my $ua = LWP::UserAgent->new;

  my $req = HTTP::Request->new(GET => 'http://www.linpro.no/lwp/');
  $req->header(Accept => 'text/html');

  # send request to server and get response back
  my $res = $ua->request($req);

  # check the outcome
  if ($res->is_success) {
     print $res->content;
  } else {
     print "Error: " . $res->status_line . "\n";
  }

The I<HTTP::Daemon> class provides the corresponding interface for LWP
based server applications.  Through instances of this class a server
application will get hold of a connection initiated by a client and
will be able receive I<HTTP::Request> objects from this connection and
send back I<HTTP::Response> objects.  Since the client and server
interface use the same message objects it is trivial to write simple
proxy[11] type of applications [12].

Features of libwww-perl include:

=over 3

=item *

Support for http, https, gopher, ftp, file,
data, mailto and news within the HTTP framework.

=item *

Basic and Digest authorization

=item *

Automatic redirect handling

=item *

Communication thorugh proxies (http-only)

=item *

Handling of URLs (both absolute and relative)

=item *

RobotRules (robots.txt)

=item *

A few command line clients.

=item *

Coexistence with Tk

=back


=head1 LWPng design

[in here, should "we" not really be "I"?]

It became evident that a major redesign of the underlying protocol
modules and the main interfaces was needed in order to support
HTTP/1.1 clients well. The major shift was that we now wanted to be
able to transparently support multiple persistent connections and that
these connections should be used efficiently (i.e. we should be able
to support pipelining too).

As for LWP5, the programming interface still ought to hide the details
of connection creation and destruction, but in order to make the
library able to efficiently utilize the multiple persistent
connections it has to have more than a single request to work with at
time.  The main idea would be that the application fed the library
with all the request objects to be carried out and that the library
would try to use its connections to the servers as optimally as
possible.  The optimization would be guided by various parameters
(throughput, speed, limit number of connections, etc.).

Some other design goals and guidelines included.

=over 2

=item *

The abstractions provided should be fairly high level.  The
HTTP::Request and HTTP::Response object interfaces of LWP5 have shown
themselves to work well and be valuable.  We still wanted a design
based on passing these objects around.

=item *

The redesigned library should be no more difficult than the old LWP5
to use.  The application programmer should not have to work harder.

=item *

The redesigned library should be backwards compatible with LWP5.  Old
applications should continue to run, but it is generally OK if they do
not run as efficiently as applications that have been rewritten to the
new interface.

=item *

The library implementation should be efficient.  The main issues are
startup time for applications (i.e. not too much unused source code
for perl to compile), and efficient use of the network connections and the
operating system (i.e. not many small read/write requests and no
polling.)

=item *

We wanted to use this opportunity to generalize some parts of the
interfaces.  For instance the old $ua->from and $ua->agent
methods can be generalized to something that is able to set up default
headers that are added to requests before they are sent out.  Having
this also solve much of the problem of setting up authorization
headers in request.

=item *

Optional features of the library should add minimal penalty to
applications that don't use them.

=item *

Most features of the library should be made optional.

This hopefully interacts well with the preceding point and should
allow a wider range of HTTP client applications to be built.  The
library can be comprehensive and feature rich and still usable by
small/simple applications that mainly care about speed.  They should
not shy away from LWP because it is too big and too slow to start.

=item *

"Easy things should be easy, hard things possible." [ref?] This is a Perl
slogan that I agree with and that also hopefully applies to this
design.

=item *

There should be minimal bindings between the modules and classes
within the library.  One should be able to use only the wanted part of
the library and individual modules should be usable in other contexts
than LWP.

=item *

There should be no need for signal handling and no use of alarm to
implement timeouts.

One of the things that created much problems for LWP5 was that it
initially used alarms to implement timeouts.  This was problematic both
because alarms are not available everywhere and because the perl signal
handling is not reliable.

=item *

Happy coexistence with the Tk module.  One should be able to write
client applications that have GUIs.

=back

The last item in the list above was one of the reasons why we early
concluded that the redesign should be based on an event driven
framework.


=head1 Event driven programming

A prerequisite for supporting the persistent connections that
HTTP/1.1 requires, is to be able to handle both reading and writing
from multiple network connections at the same time.  One would also
like to manage idle connections with some timeout and to notice
when/if the server decides to close the connections.  These
requirements basically mean the adoption of an event driven model or
a model based on separate threads of control.  We have chosen to go
for the event driven model.  Thread support is still new to Perl
and will not work everywhere when available.  An event-driven
framework will continue to work with threaded Perls.  A threaded
framework would require a thread enabled Perl to run.

[Mention problems with event oriented programming.  Must explicitly
store lot of state between invocations of the event handlers.
Handlers must be written to return quickly or special care must be
taken when allowing prompting/nested event loops.  With an threaded
environment the state can be embedded as the natural flow the program,
but one will experience new problems related to synchronization and
protecting against races.]

Let us start by investigating the impact of the event driven framework
on the overall LWP programming model.  The basic model for sending
requests and receiving responses in LWP5 used to be:

  $res = $ua->request($req);   # return when response is available
  if ($res->is_success) {
      #...
  }

With the new event driven framework it becomes:

  $ua->spool($req1);   # returns immediately
  $ua->spool($req2);   # can send multiple request in parallel
  #...

  mainloop->run;       # return when all connections are gone

Request objects are created and then handed off to the $ua which will
queue them up for processing.  As you can see, there is no longer any
natural place to test the outcome of the requests since the spool()
method returns before the response is available.  What happen is that
the requests live their own lives and they will be notified (though a
callback method call) when the corresponding responses are available.
The application programmer will have to set up handlers (in the
requests) that react to these events.

Luckily, this does not mean that all old programs must be rewritten.
The following show one way to emulate something very similar to the old
behaviour:

  my $req = LWP::Request->new(GET => $url);

  # $res = $ua->request($req);
  my $res;
  # set up a handler to be invoked when the response is available.
  $req->{done_cb} = sub { $res = shift; };

  $ua->spool($req);
  mainloop->one_event until $res;  # runs until response is available

  if ($res->is_success) {
      #...
  }

and this will in fact be used to emulate the old $ua->request() and
$ua->simple_request() interfaces for compatibility purposes.

The current LWPng implementation and the examples above are based on
the event loop implementation provided by the LWP::EventLoop class.
It is small, simple and supports exactly what LWPng needs and not much
more.  The main problem is that this introduces yet another event loop
and that it will create problems if the application want to use LWPng
together with modules based on a different event loop implementation.

[Discuss other event loops in Perl modules.  The one provided by Tk.
Grahams Event.  EventServer.  And chances for getting a standard
eventloop mechanism adopted by the Perl core.  Tcl have done this.]


=head1 Major classes

LWPng continues in the object oriented tradition of LWP5 and it adds
some new classes.  Some of these replace the corresponding classes in
LWP5.  Some add features not present before.

One important design criteria is to stay backwards compatible.  It
means that the old interfaces must be kept and if we want to clean up
an interface we basically have to start afresh with a new class
name. This allows old code to continue to work because it still use
the old names.  Often it is a good idea to re-implement the old
interfaces on top of the new interface. This allows us to keep
backwards compatibility, get one place to fix bugs and at the same
time allow new code to not suffer from compatibility bloat.  It also
works as validation of the generality of the new interfaces.

The classes that have changed name and interfaces are:

=over 2

=item *

The old LWP::UserAgent has become LWP::UA.  The name was changed
because we wanted to make a general cleanup of the interface.  The
name change also makes the transition period easier as the old LWP5
library can be installed together with the new library.

=item *

The old LWP::Protocol::* modules have been replaced with LWP::Conn::*
modules.  The event oriented framework requires a completely different
interface towards and from the low-level protocol modules.  Both
versions must be able to work side by side for some time.

=item *

The LWP::Authen modules have also changed interface and therefore name.
We have kept the prefix, but will now use all lower case for the
scheme name part.

=back

Completely new classes include:

=over 4

=item LWP::Request

This is a subclass of HTTP::Request that allows us to attach response
handlers and callbacks to these objects.  Basically all the parameters
given (and returned) by the old $ua->request method must now be
represented as attributes of the request object.

=item URI::Attr

This class make it possible to attach attributes based on
hierarchical levels of the URI name space.  It is used for various
configurations and for remembering facts about places in this space.
The main benefit is that it allows more generalizations of the
interface.
[Really Neat!]

=item LWP::Hooks

LWP::Hooks is a mixin class that allows handlers to be dynamically
registered on the object and executed.  LWP::UA and LWP::Request
inherit its methods.

=item LWP::StdSched

Policy decisions about how many and which connections
to set up or tear down at given point are delegated to a special
scheduler object by the LWP::UA.  This arrangement allow this behaviour
to be easily replaced or updated.  The LWP::StdSched is a simple
scheduler that tries to adhere to various limits on the number of
connections to create.

=item LWP::Sink

HTTP concepts like chained Transfer-Encoding and
Content-Encoding suggest that we need a way to transform the message
content back to its original form.  Since we also want to be able to
handle arbitrary sized content and to be able to make the content
available to the application as early as possible, a stream based
organization of transformation modules is handy.  The LWP::Sink is a
base class for the the input side of a stream module.

=item LWP::EventLoop

The eventloop class has been mentioned before.  It is basically just a
wrapper around the select system call.

=back

We will now investigate the major interfaces of some of these classes
in some more detail.

=head2 LWP::UA

The LWP::UA represents the main interface of the client library.  The main
entry point is the spool() method.  All requests to be processed by the
library enter through this "gate".  Before a request is handed over to some
protocol module, the LWP::UA will invoke any I<spool_handlers> registered.
The handlers are simply a list of subroutines and can be registered
dynamically by the application.

These handlers provide the main strategy of how we implement optional
features and how we achieve zero overhead for applications that don't
use the features.  The bare LWP::UA is only capable of doing the
following basic things:

=over 3

=item 1.

It provides the spool() method, and when it is invoked...

=item 2.

It knows how to run any handlers registered.

=item 3.

If no handler signaled that the request has been handled, then
it knows how to dynamically load a protocol module by looking at the scheme
of the URL and to pass the requests to it.

=item 4.

It tells the scheduler object to take some action ($sched->reschedule).

=back

[One might argue that 3. and 4. could also be replaced by one or more
handlers.]

The handlers are invoked with a reference to the UA and a reference to the
request as arguments.  If a handler returns a TRUE value, then it signals
that the request has been handled and no further handlers are to be invoked
for it.  Handlers are also used to modify the request on its way (for
instance to add headers).  They can register response callbacks or response
handlers to be triggered when the response is available.

[One can contrast this with handlers within the Apache web server for
instance.  The main problem with the solution above is that we really
ought to be able to control the order handlers are applied.  Apache
solves this by assigning handlers to named classes and the order
between classes are fixed.  Handlers could also be attached to the
URI::Attr tree.  That would allow a different set of handlers to be
invoked for different URIs.]

The following handlers are currently provided by the library.
Handlers which are not used do not have to be loaded
(i.e. Perl does not waste time compiling their code).

=over 4

=item default_headers

This handler adds static headers to a request where these headers are
not already present.  It is for instance used to add headers like
C<User-Agent> and C<From>.

=item date

This handler adds a C<Date> header to the request if applicable.  Not really
very useful, but it shows how to write small handlers to cope with headers
that the I<default_headers> handler can't do.

=item authentication

This handler tries to add an C<Authorization> header to the request that
we know might need it.  It looks up the realm for the URL and map this to
some Authen object that can add the corresponding header.  This works
together with the Authenticate response handler.

=item proxy

This handler tries to set the proxy attribute of a request.  The proxy
configuration might indicate that some URLs are to be passed through a
proxy.  It can also add a C<Proxy-Authorization> header to the request.

=item head_parser

This handler registers a response data handler with the request.  The
registered handler will create an HTML::Parser object if the response
contains an HTML document and pass the first few chunks of document data
through it.

=item cookies

This handler will let an HTTP::Cookies object add one or more
C<Cookie> headers to the request and will also register a response
callback that will let the HTTP::Cookies object extract any
C<Set-Cookie> headers.

=back

The handlers currently implemented only modify the request on its way
to the server.  Some other uses of spool handlers might include:

=over 4

=item local cache

check if we have a local copy of the response and return it instead.
If no valid local copy exists register a response handler to update or
validate the local cache.  Might also add C<If-None-Match> or
C<If-Modified-Since> headers to the request when we have a stale local
copy.

=item specific scheme handling

an application might for instance want to handle <about:> URLs similar to
what Netscape does by registering a handler.

=item url rewriting

implement automatic fast redirection inside the client

=item netnanny

block indecent parts of the URI space

=back

Many of the handlers use the common URI::Attr object member of the UA
to obtain their configuration information.

=head2 URI::Attr

For many situations we have found a need to set up configuration
parameters and other attributes related to the hierarchal URI name
space.  Many of the handlers should work differently depending on
scheme, domain, server or path.  For example the authentication
handler might want to remember "realms" per server and remember which
path prefixes that is protected within the different realms.

The URI::Attr class instances are trees of hashes.  A specific
absolute URI defines a path in the URI::Attr tree and the main
operation of URI::Attr is to return all hashes found on this path.
This allow us to efficiently look up all attributes that are relevant
to a specific URI and to be able to override attributes at lower
hierarchal levels of the URI name space.

The LWP::UA object has a URI::Attr instance as a member.  It also
provides direct access to this member through the methods
$ua->uri_attr_plain, $ua->uri_attr_update.  Configuration for all the
handlers and the protocol machinery are placed within this tree.

Let's show a simple proxy configuration as an example.  We might want
all HTTP request to go through our caching proxy, but not for request
to servers within our local domain.  This can be express like this
(assuming our local domain is I<.perl.com>):

  $ua->uri_attr_update(SCHEME=>"http:")->{proxy} = "http://proxy.perl.com";
  $ua->uri_attr_update(DOMAIN=>"http://dummy.perl.com/")->{proxy} = undef;

The proxy handler can then simply find out if a request needs to go
through a proxy with a call like this:

  $proxy = $ua->uri_attr_plain($url, "proxy");

This will return the name of the proxy server to use or C<undef> if no
proxy is to be used.


=head2 LWP::Request

The spool() method of LWP::UA accepts LWP::Request object references as
argument(s).  The LWP::Request class is derived from the HTTP::Request
class and inherit all its attributes.  The reason we use a subclass is
that it needs to support some callback methods that are invoked during
reception of the response from the server.  There are two such
methods:

   $req->response_data($data, $res);
   $req->response_done($res);

The response_data() callback method is invoked repeatedly as parts of
the content of the response becomes available.  The first time it is
invoked is right after the headers in the response message has been
parsed.  At this point $res will be a reference to an HTTP::Response
object with response code and headers initialized, but the message
content will be empty.  There is no guarantee that this method will be
called at all for a given request.

The default implementation of response_data() will run any
I<response_data> hooks and will call the registered data callback
function if it exists.  If no data callback function is defined, then
data is simply appended to the content of the response message.

The response_done() callback method is invoked when the whole response
has been received.  It is guaranteed that it will be invoked exactly
once for each request spooled (even for requests that fails.)

The default implementation of response_done() will run any
I<response_done> hooks.  Then it will try to run any
I<response_handlers>.  If none of the handlers signaled that the
response has been handled (for instance by sending a followup
request), then we either call the done callback function or we
"deliver" the response by calling the $ua->response_received($res)
method.

Applications can either subclass LWP::Request, to provide their own
versions of response_data() and response_done(), or they can just
register handlers and callback functions.  The last option is probably
to be prefered.

There are two other attributes in LWP::Request worth a mention here;
The $req->proxy field is simply the name of the proxy where to send
the request and the $req->priority field can be used to make some
request more important than others.

Again, the handlers allow more features to be optional and ensure
minimal overhead for applications that don't use them.  Currently, the
following handlers are provided:

=over 4

=item redirect handler (response_handler)

This is a handler that makes sure that the library automatically and
transparently follows any redirects responses.  If it kicks in, it will
create a follow-up request as a copy of the current request, modify
the URL or proxy setting and then respool it with the UA.

=item authentication handler (response_handler)

This is a handler that deals with "401 Unauthorized" or "407 Proxy
authentication required" responses.  It tries to dynamically load the
LWP::Authen module that corresponds to the authentication scheme (only
Basic and Digest are currently provided) and then lets the loaded
module deal with asking the user for a user name and a password and for
setting up the C<Authorization> or C<Proxy-Authorization> header in a
copy the request.  If all works well the new request is respooled with
the UA.

=item head parser (data hook)

The head parser looks at the <HEAD> section of HTML documents to
extract header fields like C<Content-Base> and C<Title>.

=item extract_cookies (done hook)

If the I<cookies> spool handler is enabled, then it will register a
response_done hook in order to look at the C<Set-Cookie> headers of
all responses.

=back

=head2 LWP::Conn::*

The guts of the library is in the LWP::Conn classes.  This is where
all the low level protocol handling takes place.  Each protocol is
implemented by its own LWP::Conn class.  For instance the HTTP
protocol is implemented by the LWP::Conn::HTTP class.  Instances of
these classes represent a single (logical) network connection to a
corresponding kind of server.  The scheduler within the UA is
responsible for deciding how many connections to set up for each of
the servers we are going to communicate with.

It is these connection objects that drive the activity within the
library.  As network and timer events happen we get callbacks into the
connection objects and these will make further (higher level and
fewer) callbacks to the rest of the library.

[[fig1.ps]]

One other source of activity within the library is the application
itself.  It can either spool further requests or it can kill running
requests (and connections).

A HTTP::Conn object registers socket and timer callbacks with the
EventLoop.  The rest of its interface to the outside world is though a
single manager object.  There is a simple well defined interface that
the manager must implement.  Though this interface it must return
request to be performed and it is told about the overall state of the
connection and when the connection dies.  This allows a single manager
to manage several connection objects.

This simple interface makes it easy to use the HTTP::Conn
implementations directly without the rest of the library.

=head2 LWP::Conn::HTTP

The LWP::Conn::HTTP module implements the HTTP protocol for LWPng.  A
single LWP::Conn::HTTP instance represents a single network connection
to an HTTP server.  Several request/response exchanges can take place
over this single connection. Pipelining of requests is supported too.

The design of this module was very much inspired by the "State"
pattern described in [ref "Design Patterns: Elements of Reusable
Object-Oriented Software" (Gamma et.al)].  The main intent of this
pattern is described like this:

  Allow an object to alter its behaviour when its internal state
  changes.  The object will appear to change its class.

This is usually achieved by having the main object (the connection)
maintain a reference to some state object that represents the current
state.  All state specific methods are then delegated to this state
object, and state changes involve updating the reference to the state
object.

For libwww-perl, Perl's dynamic approach to object orientation came
handy.  With Perl we can actually (and efficiently) change the class
of an existing object at run-time.  This means that a Perl
implementation can simplify the "State" pattern a lot.

Each state that the HTTP connection object can be in is represented by
its own LWP::Conn::HTTP subclass and state transitions are simply a
calls to the C<bless> builtin.  The use of classes also make it easy
to express sub-states (as subclasses) that behaves mostly like its
base state, but modify some of its behaviour.

[Love it :-]
The states used by LWP::Conn::HTTP are:

=over 4

=item Connecting

In this state we have called the non-blocking connect(2) and got
EINPROGRESS back.  We wait until the socket becomes writable which
usually means that the connection attempt was successful.  On success
we switch to the Idle state and call $self->activate().

=item Idle

In this state we have nothing to do.  We wait until timeout() or
somebody calls the activate() method.  We must also monitor the
network connection so that we notice if the server decides to close it
before we do.

If the activate() method is invoked then we try to obtain a new
request to send.  If this succeeds then we switch to the Active state.

=item Active

In this state we are sending or or more requests and are prepared to
read any response that comes back.  When the headers of a response has
been received, they are parsed and we switch to one of the following
sub-states depending on the how the message content are to be
delimited.  When the whole message content has been received we try to
obtain another request to send and depending on the outcome of this we
switch back to the Active or the Idle state.

=item ContLen

This is an Active subclass.  We maintain a counter of the number of
bytes to expect for the message content and we read data until this
counter reach zero.

=item Chunked

This is an Active subclass.  We must read and parse chunk headers,
then read the corresponding number of chunk bytes.  This repeats until
a 0-chunk is received.  Finally we must be prepared to parse trailer
headers for the response.

=item Multipart

This is an Active subclass.  We read content data until the specified
boundary byte pattern is found.

=item UntilEOF

This is an Active subclass. We read content data until the server
closes the connection.  This is also the HTTP/1.0 behaviour.

=item  Closed

This is the state that the connection enters when it is dies and the
socket is closed.  No method calls are allowed any more.

=back

The LWP::Conn::HTTP constructor takes the name of the server host and
the port to connect to as arguments.  It creates a non-blocking socket
and tries to connect to the specified server and will then either
enter the Connecting or Idle state depending on what connect(2)
returns.  We also register timeout callbacks which makes sure
that this connection instance looks after itself.

The following picture illustrates the state transitions that take
place:

[[state.ps]]

=head1 LWP::Conn::FTP

The LWP::Conn::FTP module use a similar approach, but it has many
more states to represent the conversation that have to take place on
the command channel.  The concept of representing persistent
connections within the library has also shown to be a big win for the
FTP support.  It is now straightforward to provide persistent FTP
connections that do not tear down the command socket after each
request.


=head1 Some benchmarks

LWPng is still alpha software, so it might be a bit premature to do
serious benchmarking of it.  There has really not yet been any work
on trying to optimize the library for speed, since we are still
focusing on getting the programming interface defined, but it might be
interresting to see how we are doing so far.

The test below is based on a simple script that fetch a single HTML
page, parse it and then fetch all images referenced.  This is similar
to what a graphical browser whould have to do to load a page.  We
measure the complete downloading time using the Unix 'time' command
which report elapsed real time as well as how much CPU time is used.
We don't go into deeper detail such as looking at the number of TCP
packets generated or the number of system calls invoked.

These tests results have been made on a 90Mhz i586 running RedHat
Linux 4.  We have used perl5.004_04, libwww-perl-5.32 and
lwpng-alpha-0.20.  The tests are:

=over 3

=item LWP5

The page fetcher script using the old libwww-perl-5 library.  The
script will fetch the HTML page and the images in sequence and create
a new connection for each resource.

=item LWPng

The page fetcher script using the new LWPng interface.  The script
will start fetching the images as soon as the corresponding part of
the HTML document has been received.

How the LWPng library behaves depend on various parameters.  C<MaxConn>
is the number of parallel connections we can have to a single server.
C<ReqLimit> sets a limit on the number of requests we will send on a
single connection.  Setting this value to 1 effectively disables persistent
connections.  C<ReqPend> sets a limit on the number of requests we can
have outstanding on a connection before we must wait for a response.
Setting this value to 1 effectively disables pipelining.

The script has been tested with the
following combinations of the parameters:

     MaxConn   ReqLimit   ReqPend
   +---------+----------+----------
 A |    1          1         1
 B |    2          1         1
 C |    1        100         1
 D |    1        100         3
 E |    2        100         3

=item SOCK

A simplifed version of page fetcher script that just hard-code
downloading of the specified URLs over a single persistent
IO::Socket::INET connection.  All requests are written using a single
print and then we read the responses until the server close the
connection.  The numbers for this test should indicate an upper limit
on the downloading speed we can hope to achieve with Perl.

=back

gran --> furu [get-page-lwp5 http://furu/ 5], 3 images

 LWP5)    0.94user 0.31system 0:02.49elapsed 50%CPU
 LWPng-A) 2.61user 0.23system 0:03.61elapsed 78%CPU
 LWPng-C) 2.38user 0.31system 0:03.57elapsed 75%CPU
 LWPng-D) 2.36user 0.26system 0:03.49elapsed 74%CPU
 LWPng-E) 2.30user 0.25system 0:03.22elapsed 79%CPU
 SOCK)    0.28user 0.05system 0:01.40elapsed 23%CPU

furu --> www.microsoft.com, [17 images]

 LWP5)    3.86user 0.30system 0:21.07elapsed 19%CPU
 LWPng-A) 6.25user 0.39system 0:22.98elapsed 28%CPU
 LWPng-A) 6.17user 0.38system 0:21.85elapsed 29%CPU
 LWPng-C) 5.66user 0.40system 0:17.20elapsed 35%CPU
 LWPng-C) 5.70user 0.37system 0:16.56elapsed 36%CPU
 LWPng-D) 5.58user 0.38system 0:13.82elapsed 43%CPU
 LWPng-D) 5.55user 0.39system 0:13.92elapsed 42%CPU
 LWPng-E) 5.62user 0.45system 0:13.46elapsed 45%CPU
 LWPng-E) 5.87user 0.33system 0:13.09elapsed 47%CPU
 SOCK)    0.72user 0.08system 0:10.65elapsed 7%CPU
 SOCK)    0.73user 0.10system 0:10.89elapsed 7%CPU

=head1 Conclusions

This article has discussed the design of HTTP/1.1 support for the next
generation of the LWP modules.  The new design look promising.  It
allows you to write client applications that manage multiple persistent
connections to its peer servers.

=head1 References

=over 4

=item [0]

The LWP homepage - <http://www.linpro.no/lwp/>

=item [1]

RFC 1945 - "Hypertext Transfer Protocol -- HTTP/1.0.", Berners-Lee,
T., Fielding, R. and H. Frystyk., MIT/LCS, UC Irvine, May 1996.

=item [2]

RFC2047 - "MIME (Multipurpose Internet Mail Extensions) Part
Three: Message Header Extensions for Non-ASCII Text", Moore, K.,
University of Tennessee, November 1996.

=item [3]

RFC 2068 - "Hypertext Transfer Protocol -- HTTP/1.1", Fielding, R.,
Gettys, J., Mogul, J., Frystyk, H., Berners-Lee, T., UC Irvine,
Digital Equipment Corporation, M.I.T., January, 1997.

=item [4]

draft-ietf-http-v11-spec-rev-03.txt - "Hypertext Transfer Protocol --
HTTP/1.1", Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter
L., Leach P., Berners-Lee, T., HTTP Working Group, March, 1998.

=item [5]

NOTE-pipelining-970624 - H. Frystyk et.al

"Network Performance Effects of HTTP/1.1, CSS1, and PNG", Frystyk
Nielsen, Gettys, Baird-Smith, Prud'hommeaux, Lie, Lilley. W3C, 1997.

<http://www.w3c.org/Protocols/HTTP/Performance/Pipeline.html>

=item [6]

<http://www.w3c.org/Protocols/HTTP-NG/>

=item [7]

MOMspider

=item [8]

libwww-perl-0.40 - Roy Fielding

=item [9]

ParallelUserAgent - Marc Langheinrich

=item [10]

w3c-libwww-perl - H. Frystyk

=item [11]

An article that explains proxies - W3C web perhaps...

=item [12]

Anon... Proxy - Randal


=item [15]

"Why Threads Are A Bad Idea (for most purposes)", John K. Ousterhout,
1996 USENIX Technical Conference
<http://www.scriptics.com/people/john.ousterhout/>

=item [16]

"Design Patterns - Elements of Reusable Object-Oriented Software",
E. Gamma, R. Helm, R. Johnson, J. Vlissides.  1995 Addison Wesley.

=back


=cut
