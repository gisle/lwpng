
This is supposed to be an article about libwww-perl-6 for the Perl
conference in august 1998.

# $Id$

=pod

Title: LWPng - The next generation of the libwww-perl library

Author: Gisle Aas <aas@sn.no>

=head1 Abstract

This article describe a redesign of the libwww-perl library in order
to provide support for writing HTTP/1.1 clients.  It allow client
applications to utilize multiple persistent connections to the servers
it communicate with.  The redesign is based on the adoption of an
event loop framework.

=head1 Introduction

The libwww-perl package has been quite successful at implementing a
wide range of web client applications and also as a support tool for
server side programs and programmers.  One important feature that it
has been lacking is support of the new version of the HTTP protocol,
HTTP/1.1.

=head1 A short history of HTTP

HTTP is a simple protocol based on the request/response paradigm.  A
client establishes a connection with a server and sends a request
message to the server.  The server then returns a response message.

HTTP started out as an extremely simple protocol where the client
connected to a server, sent a line with "GET <name>" and the server
returned the <name> resource and closed the connection.  This version
of the protocol has afterwards been dubbed HTTP/0.9.

The next revision gave us HTTP/1.0, which is still what is deployed in
most servers and clients today [ref].  It adds a protocol version
number to the request line from the client and adds MIME-like messages
for both the request from the client and the response from the server.
This makes it possible to add extra information about
request/responses and to carry meta-information about the content of
these messages.  Responses now also start with a status line with a
status code that encode the overall outcome of the request.  These
enhancements make the protocol extensible.

The next step was/is HTTP/1.1 which tries to fix some of the
shortcommings of the HTTP/1.0 protocol [ref]. One simple but important
change is that the Host header is now mandatory. This make it possible
to serve multiple domains from a single server without allocating a
new IP-address to each.  Another change is support for partial content
messages.  The support for caching and proxies has also been much
clarified and improved on.  There is also a standard mechanism of
switching away from HTTP/1.1 to some other (hopefully more suitable)
protocol on the wire.

The most important change with HTTP/1.1 is the introduction of
persistent connections.  This means that more than one
request/response exchange can take place on a single TCP connection
between a client and a server.  This improves performance and
generally interacts much better with how TCP works underneath.  In
order to be able to do this, the peers must have some way to tell the
extent of the messages on the wire. In HTTP/1.0 the only way to do
this was by using the Content-Length header and by closing the
connection (which was only an option for the server).  Use of the
Content-Length header is not appropriate when the length of the
message can not be determined in advance.  HTTP/1.1 introduce two new
ways to delimit messages; the chunked transfer encoding and the self
delimiting multipart content types.  The chunked transfer encoding
means that the message is broken into chunks, each of arbitrary size
and each preceded by a line specifying the number of bytes in the
chunk.  The multipart types use a special boundary bytepattern as a
delimiter for the messages.

With persistent connections one can improve performance even more by
the use of a technique called "pipelining".  This means that the
client sends multiple requests down the connections without waiting
for the response of the first request before sending the second and so
on.  This can have a dramatic effect on the thoughput for high latency
links. [ref NOTE-pipelining-970624]

Some of the HTTP/1.1 features are also deployed in HTTP/1.0 clients
and servers.  Persistent connections can sometimes be used with
HTTP/1.0 if the clients sends a "Connection: Keep-Alive" header.  Most
of todays HTTP/1.0 clients send the Host header.

HTTP/NG is still a research project and an attempt to take a more
radical approach.  The main "features" is making the protocol binary
in order not to waste bytes on long human readable headers and direct
support for multiplexing over a single network connection.  It is not
clear whether this is such a big win. [ref]

=head1 History of libwww-perl

The libwww-perl project started on the first WWW conference in Geneva
where Martijn Koster discussed MOMspider with Roy Fielding.  Martijn
suggested that it would be a good thing if the reuseable components of
this program was broken out into a library.  The result was the
libwww-perl library for perl4 that Roy maintained (and still does).

At one point both Gisle and Martijn had made their own modulifications
of Roy's library to better suit the possibilities that perl5 provided.
We joined forces and made several alpha releases together.
Unfortunately Martijn had a little disagreement about the rights to
library souce code with his employer at that time.  This was the main
reason Gisle ended up as the maintainer of the package.

The LWP:: module name was introduced by Martijn in one of the
alpha releases.  It was early pointed out that this name could be
confused with what some implementations of threads called themselves,
but no better name alternatives emerged.  The last messages on this
matter was <"6362 Tue Jul 18 09:59:46 1995"@mhs-relay.ac.uk> where
Martijn concluded that "OK, so we all agree lwp stinks :-)".  The name
stuck.

At 1996-05-26 we made the first non-beta release of libwww-perl.  It
was called release 5.00 because it was for perl5 and in order to make
some room for Roy to maintain libwww-perl for perl4 which at that time
was (and still is) called libwww-perl-0.40.

In the two years that has passed since that time lots of bugs has been
fixed and some features added, but nothing radical has happened.  We
have not been eager to try to adopt HTTP/1.1 features because it
seemed clear that decent support could not be achieved without a
larger restructuring of how the basic protocol services was
implemented.

One important work that inspired the rewrite described here was Marc
Langheinrich's ParallelUserAgent implementation.  It extended
libwww-perl with the possibility to access multiple servers (or have
multiple connections to the same server) at the same time. [ref]

In the november 1997 Gisle started on a rewrite of how the basic
services provided by libwww-perl worked.  The goal was to provide full
HTTP/1.1 client support and at the same time make the library both
more flexible and (optionally) more lightweight.  Little
happened until march 1998, but then I finally got opportunity and
currage enough to start working on this fulltime and it is by this time
quite useable.  This work is currently distributed under the name
LWPng, but is expected to become libwww-perl-6 when its beta phase is
over.


=head1 A short introduction to libwww-perl-5

The libwww-perl library is based on HTTP style communication.  The
main model is that all requests through any protocol module are forced
into an HTTP straightjacket. This makes things very easy, consistent,
and nice.  This model is also what libwww-perl has inherited from and has
in common with w3c-libwww [ref].

LWP provide an object oriented model of HTTP style messages that are
passed between servers and clients.  The I<HTTP::Request> class models
the message sent from a client to a server.  The I<HTTP::Response>
class models the message send back from a server to a client.  On
their way between a client to a server these messages are converted to
the actual protocol on the wire which again will depend on what kind of
server we are accessing (i.e. does not have to be HTTP).

Instances of the I<LWP::UserAgent> class are created by client
applications and have the role as the interface between the
application and a network of accessible servers.  The
I<LWP::UserAgent> provide the request() method that accepts an
I<HTTP::Request> object as argument and will (eventually) return a
I<HTTP::Response> object when the corresponding server returns an
answer.

The canonical example of LWP client usage looks like this:

  use LWP::UserAgent;
  my $ua = LWP::UserAgent->new;

  my $req = HTTP::Request->new(GET => 'http://www.linpro.no/lwp/');
  $req->header(Accept => 'text/html');

  # send request to server and get response back
  my $res = $ua->request($req);

  # check the outcome
  if ($res->is_success) {
     print $res->content;
  } else {
     print "Error: " . $res->status_line . "\n";
  }

The I<HTTP::Daemon> class provide the corresponding interface for LWP
based server applications.  Through instances of this class a server
application will get hold of a connection initiated by a client and
will be able receive I<HTTP::Request> objects from this connection and
send back I<HTTP::Reponse> objects.  Since the client and server
interface use the same message objects it is trivial to write simple
proxy[ref] type of applications [reference to Randals proxy for
WebTechniques].

[Feature list?]


=head1 LWPng design

It became evident that a major redesign of the underlying protocol
modules and the main interfaces was needed in order to support
HTTP/1.1 clients well. The major shift was that we now wanted to be
able to transparently support multiple persistent connections and that
these connections should be used efficiently (i.e. we should be able
to support pipelining too).

As for LWP5, the programming interface still ought to hide the details
of connection creation and destruction, but in order to make the
library able to efficiently utilize the multiple persistent
connections it had to have more than a single request to work with at
time.  The main idea would be that the application fed the library
with all the request objects to be carried out and that the library
would try to use its connections to the servers as optimally as
possible.  The optimization would be guided by various parameters
(throughput, speed, limit number of connections, etc.).

Some other design goals and guidelines included.

=over 2

=item *

The abstractions provided should be fairly high level.  The
HTTP::Request and HTTP::Response object interfaces of LWP5 have shown
themselves to work well and be valuable.  We still wanted a design
based on passing these objects around.

=item *

The redesigned library should be no more difficult than the old LWP5
to use.  The application programmer should not have to work harder.

=item *

The redesigned libraray should be backwards compatible with LWP5.  Old
applications should continue to run, but it is generally OK if they do
not run as efficiently as applications that have been rewritten to the
new interface.

=item *

The library implementation should be efficient.  The main issues are
startup time for applications (i.e. not too much unused source code
for perl to compile).  Effient use of the network connections and the
operating system (i.e. not many small read/write requests and no
polling.)

=item *

We wanted to use this opportunity to generalize some parts of the
interfaces.  For instance the old $ua->from and $ua->agent
methods can be generalized to something that is able to set up default
headers that are added to requests before they are sent out.  Having
this also solve much of the problem of setting up authorization
headers in request.

=item *

Optional features of the library should add minimal penalty to
applications that don't use them.

=item *

Most features of the library should be made optional.

This hopefully interacts well with the preceding point and should
allow a wider range of HTTP client applications to be built.  The
library can be comprehensive and feature rich and still useable by
small/simple applications that mainly care about speed.  They should
not shy away from LWP because it is too big and too slow to start.

=item *

"Easy things should be easy, hard things possible."  This is a Perl
slogan that I agree with and that also hopefully applies to this
design.

=item *

There should be minimal bindings between the modules and classes
within the library.  One should be able to use only the wanted part of
the library and individual modules should be usable in other context
than LWP.

=item *

There should be no need for signal handling and no uses of alarm to
implement timeouts.

One of the things that created much problems for LWP5 was that it
earlier used alarms to implement timeouts.  This was problematic both
because it is not available everywere and because the perl signal
handling is not reliable.

=item *

Happy coexistence with the Tk module.  One should be able to write
client applications that have GUIs.

=back

The last item in the list above was one of the reasons why we early
concluded that the redesign should be based on an event driven
framework.


=head1 Event driven programming

A prerequisite for supporting the persistent connections that
HTTP/1.1 requires, is to be able to handle both reading and writing
from multiple network connections at the same time.  One would also
like to manage idle connections with some timeout and to notice
when/if the server decide to close the connections.  These
requirements basically means the adoption of an event driven model or
a model based on separate threads of control.  We have chosen to go
for the event driven model.  Thread support is still new to Perl
and will not work everywhere when available.  An event-driven
framework will continue to work with threaded Perls.  A threaded
framework would require a thread enabled Perl to run.

[Mention problems with event oriented programming.  Must explicitly
store lot of state between invocations of the event handlers.
Handlers must be written to return quickly or special care must be
taken when allowing prompting/nested event loops.  With an threaded
environment the state can be embedded as the natural flow the program,
but one will experience new problems related to synchronization and
protecting agains races.]

Let us start by investigating the impact of the event driven framework
on the overall LWP programming model.  The basic model for sending
requests and receving respones in LWP5 used to be:

  $res = $ua->request($req);   # return when response is available
  if ($res->is_success) {
      #...
  }

With the new event driven framework it becomes:

  $ua->spool($req1);   # returns immediately
  $ua->spool($req2);   # can send multiple request in parallel
  #...

  mainloop->run;       # return when all connections are gone

Request objects are created and then handed off to the $ua which will
queue them up for processing.  As you can see, there is no longer any
natural place to test the outcome of the requests since the spool()
method returns before the response is available.  What happen is that
the requests live their own lives and they will be notified (though a
callback method call) when the corresponding responses are available.
The application programmer will have to set up handlers (in the
requests) that react to these events.

Luckily, this does not mean that all old programs must be rewritten.
The following show one way to emulate something very similar to the old
behaviour:

  my $req = LWP::Request->new(GET => $url);

  # $res = $ua->request($req);
  my $res;
  # set up a handler to be invoked when the response is available.
  $req->{done_cb} = sub { $res = shift; };

  $ua->spool($req);
  mainloop->one_event until $res;  # runs until response is available

  if ($res->is_success) {
      #...
  }

and this will in fact be used to emulate the old $ua->request() and
$ua->simple_request() interfaces for compatibility purposes.

The current LWPng implementation and the examples above are based on
the event loop implementation provided by the LWP::EventLoop class.
It is small, simple and support exactly what LWPng needs and not much
more.  The main problem is that this introduce yet another event loop
and that it will create problems if the application want to use LWPng
together with modules based on a different event loop implementation.

[Discuss other event loops in Perl modules.  The one provided by Tk.
Grahams Event.  EventServer.  And chances for getting a standard
eventloop mechanism adopted by the Perl core.  Tcl have done this.]


=head1 Major classes

LWPng continue in the object oriented tradition of LWP5 and it adds
some new classes.  Some of these replace the corresponding classes in
LWP5.  Some add features not present before.

One important design criteria is to stay backwards compatible.  It
means that the old interfaces must be kept and if we want to clean up
an interface we basically have to start afresh with a new class
name. This allows old code to continue to work because it still use
the old names.  Often it is a good idea to reimplement the old
interfaces on top of the new interface. This allows us to keep
backwards compatibility, get one place to fix bugs and at the same
time allow new code to not suffer from compatibility bloat.  It also
works as validation of the generality of the new interfaces.

The classes that have changed name and interfaces are:

=over 2

=item *

The old LWP::UserAgent has become LWP::UA.  The name was changed
because we wanted to make a general cleanup of the interface.  The
name change also make the transition period easier as the old LWP5
library can be installed together with the new library.

=item *

The old LWP::Protocol::* modules has been replaced with LWP::Conn::*
modules.  The event oriented framework requires a completely different
interface towards and from the low level protocol modules.  Both
versions must be able to work side by side for some time.

=item * 

The LWP::Authen modules has also changed interface and therefore name.
We have kept the prefix, but will now use all lower case for the
scheme name part.

=back

Completely new classes include:

=over 4

=item LWP::Request

This is a subclass of HTTP::Request that allows us to attach response
handlers and callbacks to these objects.  Basically all the parameters
given (and returned) by the old $ua->request method must now be
represented as attributes of the request object.

=item URI::Attr

This class make it possible to attach attributes based on
hierarchical levels of the URI name space.  It is used for various
configurations and for remembering facts about places in this space.
The main benefit is that it allows more generalizations of the
interface.

=item LWP::Hooks

LWP::Hooks is a mixin class that allow handlers to be dynamically
registered on the object and executed.  LWP::UA and LWP::Request
inherit its methods.

=item LWP::StdSched

Policy decisions about how many and which connections
to set up or tear down at given point are delegated to a special
scheduler object by the LWP::UA.  This arangement allow this behaviour
to be easily replaced or updated.  The LWP::StdSched is a simple
scheduler that tries to adhere to various limits on the number of
connections to create.

=item LWP::Sink

HTTP concepts like chained Transfer-Encoding and
Content-Encoding suggest that we need a way to transform the message
content back to its original form.  Since we also want to be able to
handle arbitrary sized content and to be able to make the content
available to the application as early as possible a stream based
organization of transformation modules is handy.  The LWP::Sink is a
base class for the the input side of a stream module.

=item LWP::EventLoop

The eventloop class has been mentioned before.  It is basically just a
wrapper around the select system call.

=back

We will now investigate the major interfaces of these classes in some
more detail.

=head2 LWP::UA

The LWP::UA represents the main interface of the client library.  The main
entry point is the spool() method.  All requests to be processed by the
library enter through this "gate".  Before a request is handed over to some
protocol module the LWP::UA will invoke any I<spool_handlers> registered.
The handlers are simply a list of subroutines and can be registered
dynamically by the application.

These handlers is the main stategy of how we implement optional features and
how we achieve zero overhead for applications that don't use the features.
The bare LWP::UA is only capable of doing the following basic things:

=over 3

=item 1.

It provide the spool() method, and when it is invoked...

=item 2.

It know how to run any handlers registered.

=item 3.

If no handler signaled that the request has been handeled, then
it knows how to dynamically load a protocol module by looking at the scheme
of the URL and to pass the requests too it.

=item 4.

It tells the scheduler object to take some action ($sched->reschedule).

=back

[One might argue that 3. and 4. could also be replaced by one or more
handlers.]

The handlers are invoked with a reference to the UA and a reference to the
request as arguments.  If a handler return a TRUE value, then it signals
that the request has been handeled and no further handlers are to be invoked
for it.  Handlers are also used to modify the request on its way (for
instance adding headers).  They can register response callbacks or response
handlers to be triggered when the response is available.

[One can contrast this with handlers within the Apache web server for
instace.  The main problem with the solution above is that we really
ought to be able to control the order handler are applied.  The Apache
solve this by assigning handlers to named classes and the order
between classes are fixed.  Handlers could also be attached to the
URI::Attr tree.  That would allow a different set of handlers to be
invoked for different URIs.]

The following handlers are currently provided by the library.
Handlers which are not used do not have to be loaded either
(i.e. Perl does not waste time compiling their code).

=over 4

=item default_headers

This handler add static headers to a request where these headers are
not already present.  It it for instance used to add headers like
C<User-Agent> and C<From>.

=item date

This handler add a C<Date> header to the request if applicable.  Not really
very useful, but shows how to write small handlers to cope with headers
that the I<default_headers> handler can't do.

=item authentication

This handler try to add an C<Authorization> header to the request that
we know might need it.  It looks up realm for the URL and map this to
some Authen object that can add the corresponding header.  This works
together with the Authenticate response handler.

=item proxy

This handler try to set the proxy attribute of a request.  The proxy
configuation might indicate that some URLs are to be passed through a
proxy.  It can also add a C<Proxy-Authorization> header to the request.

=item head_parser

This handler register a response data handler with the request.  The
registered handler will create a HTML::Parser object if the response
contains an HTML document and pass the first few chunks of document data
through it.

=item cookies

This handler will let an HTTP::Cookies object add one or more
C<Cookie> headers to the request and will also register a response
callback that will let the HTTP::Cookies object extract any
C<Set-Cookie> headers.

=back

The handlers currently implemented only modify the request on its way
to the server.  Some other uses of spool handlers might include:

=over 4

=item local cache

check if we have a local copy of the response and return it instead.
If no valid local copy exists register a response handler to update or
validate the local cache.  Might also add C<If-None-Match> or
C<If-Modified-Since> headers to the request when we have a stale local
copy.

=item specific scheme handling

an application might for instance want to handle <about:> URLs similar to
what Netscape does by registering a handler.

=item url rewriting

implement automatic fast redirection inside the client

=item netnanny

block indecent parts of the URI space

=back

Many of the handlers use the common URI::Attr object member of the UA
to obtain their configuration information.

=head2 URI::Attr

For many situations we have found a need to set up configuration
parameters and other attributes related to the URI name space.  Many
of the handlers should work differently depending on scheme, domain,
server or path.  For example the authentication handler might want to
remember "realms" per server and remember which path prefixes that is
protected within the different realms.

The main idea of the URI::Attr class is to be able to efficiently look
up all attributes that are relevant to a specific absolute URI and to
be able to override attributes at lower hierarchal levels of the URI
namespace.

The LWP::UA object has a URI::Attr instance as a member.  It also
provide direct access to this member though the methods
$ua->uri_attr_plain, $ua->uri_attr_update.  Configuration for all the
handlers and connections are placed within this tree.

Let's show a simple proxy configuration as an example.  We want all
HTTP request to go through our caching proxy, but not for request to
servers within our local domain.  This can be express like this
(assuming our local domain is .perl.com):

  $ua->uri_attr_update(SCHEME=>"http:")->{proxy} = "http://proxy.perl.com";
  $ua->uri_attr_update(DOMAIN=>"http://dummy.perl.com/")->{proxy} = undef;

The proxy handler can then simply find out if a request needs to go
through a proxy with a call like this:

  $proxy = $ua->uri_attr_plain($url, "proxy");

This will return the name of the proxy server to use or C<undef> if no
proxy is to be used.


=head2 LWP::Request

The spool() method of LWP::UA accept LWP::Request object references as
argument(s).  The LWP::Request class is derived from the HTTP::Request
class and inherit all its attributes.  The reason we use a subclass is
that it needs to support some callback methods that are invoked during
reception of the response from the server.  There are two such
methods:

   $req->response_data($data, $res);
   $req->response_done($res);

The response_data() callback method is invoked repeatedly as parts of
the content of the response becomes available.  The first time it is
invoked is right after the headers in the response message has been
parsed.  At this point $res will be a reference to an HTTP::Response
object with response code and headers initialized, but the message
content will be empty.  There is no guarantee that this method will be
called at all for a given request.

The default implementation of response_data() will run any
I<response_data> hooks and will call the registered data callback
function if it exists.  If no data callback function is defined, then
data is simple appended to the content of the response message.

The response_done() callback method is invoked when the whole response
has been received.  It is guaranteed that it will be invoked exactly
once for each request spooled (even for requests that fails.)

The default implementation of response_done() will run any
I<response_done> hooks.  Then it will try to run any
I<response_handlers>.  If none of the handlers signaled that the
response has been handled (for instance by sending a followup
request), then we either call the done callback function or we
"deliver" the response by calling the $ua->response_received($res)
method.

Applications can either subclass LWP::Request, to provide their own
versions of response_data() and response_done(), or they can just
register handlers and callback functions.  The last option is probably
to be prefered.

There are two other attributes in LWP::Request worth metion here; The
$req->proxy field is simply the name of the proxy where to send the
request and the $req->priority field can be used to make some request
more important than others.

Again, the handlers allow more features to be optional and ensure
minimal overhead for applications that don't use them.  Currently, the
following handlers are provided:

=over 4

=item head parser (data hook)

=item extract_cookies (done hook)

=item redirect handler (response_handler)

=item authentication handler (response_handler)

=back

=head2 LWP::Conn object interface.

The guts of the library is the LWP::Conn classes.  This is where all the
action (i.e. low level protocol handling) takes place.  The basic model is
that the LWP::Conn's are what drive the activity (together with $ua->spool).


          +--> lwp::ua ---+
          |               |
      application      lwp::conn
          |               |
        (g)ui          network
          ^               ^
          |               |
          +-- eventloop --+
                  |
           external stimuli

How these can be used on their own without the rest of the library.

=head2 LWP::Conn::HTTP design.

Cool.  The flexibility of Perl continue too
suprise me.

Perhaps we need a redisign to be able to support HTTPS?  Don't let the
LWP::Conn:HTTP object be the actual handle, but use a member object
instance insted.

=head2 streams/LWP::Sink

process arbitrary sized objects and make the result
available for further processing as early as possible.


=head1 Some benchmarks

How well does it perform piplining.  Compare it with LWP5 and
w3c-libwww perhaps.


=head1 Conclusions

This article has discussed the design of HTTP/1.1 support for the next
generation of the LWP modules.  The new design look promising.  It
allow you to write client applications that manage multiple persistent
connections to its peer servers.

=cut
